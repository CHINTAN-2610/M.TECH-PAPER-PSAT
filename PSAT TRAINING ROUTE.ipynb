{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f9fab9",
   "metadata": {},
   "source": [
    "# TITLE : MODELS OF SATURATION PRESSURE FROM COMPOSITIONAL DATA MWC7+  TEMP USING MACHINE LEARNING ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed97750",
   "metadata": {},
   "source": [
    "OBJECTIVE : TRINING OF MODELS FOR FUTURE SELECTION FOR PREDICTION OF SATURATION PRESSURE USING WIDE RANGE OF COMPOSITION DATA AND THIS FILE SHOWS WORK WITH ONE LESS FEATURES (SGC7+) WHICH MULTICOLINEAR WITH MWC7+.\n",
    "\n",
    "THIS FILE AUTOMATICALLY FIT MODELS AND STORE MODELS AT GIVEN PATH \n",
    "\n",
    "IF REVIEWER WANT TO CHECK SIMILLAR MODELS USED TO PREDICT TEST OR NOT WHICH TRAINED HERE THAN IN MODEL VALIDATION FILE OPTIMIZED PARAMETER CAN BE CKECKED WHICH AVOID RETRINING WHICH TAKE A LOT TIME AS WELL AS TO CHECK DATA TRAIN AND TEST ALREADY SEPRATED AND STAROED INTO DATASOURCE FROM PREPROCESSING FILE SAME DATA USED HERE WHICH VERIFIED BY CHEKING EXCEL FILES \n",
    "\n",
    "\n",
    "ALGORITHM APPLIED : LINEAR REGRESSION, SUPPORT VECTOR MACHINE, KNN, RANDOM FOREST, DECISION TREE, XGB , ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1540939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-1ef187d9cf9b>:33: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "#DATA EXTRACTION, MANIPULATION, VIZULIZATION LIBRARY\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#STATISTICAL TOOLS LIBRARY\n",
    "import scipy.stats as stat\n",
    "import pylab \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#DATA FETURES OPERATION LIBRARY\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#MODELING LIBRARY\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#MODELLING OF DEEP LEARNING MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "#MODEL EVALUATION LIBRARY\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error\n",
    "\n",
    "\n",
    "#Model saving\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bbfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the folder path inside which training and testing file located\n",
    "path = \"C:\\\\STUDY DRIVE\\\\PSAT PAPER THESIS EDIT\\\\PSAT NEW\\\\MODEL 3\\\\DATASOURCE\\\\\"\n",
    "\n",
    "#Enter training file name\n",
    "file_name = \"TRAIN.csv\"\n",
    "\n",
    "#Enter Path where models are stored after optimization of hyperparameter\n",
    "model_path = \"C:\\\\STUDY DRIVE\\\\PSAT PAPER THESIS EDIT\\\\PSAT NEW\\\\MODEL 3\\\\MODELS\\\\\"\n",
    "\n",
    "#Enter the path where realted inforamtion from this file to export at that location\n",
    "export_data_path = \"C:\\\\STUDY DRIVE\\\\PSAT PAPER THESIS EDIT\\\\PSAT NEW\\\\MODEL 3\\\\EXPORTED DATA\\\\\"\n",
    "\n",
    "\n",
    "#Read training files\n",
    "train = pd.read_csv(path+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af82db33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H2S</th>\n",
       "      <th>N2</th>\n",
       "      <th>CO2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7+</th>\n",
       "      <th>MWC7+</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Psat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>0.10380</td>\n",
       "      <td>0.09010</td>\n",
       "      <td>0.05130</td>\n",
       "      <td>0.03280</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.2858</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>422.038889</td>\n",
       "      <td>207.006803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.04880</td>\n",
       "      <td>0.05670</td>\n",
       "      <td>0.05520</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.7067</td>\n",
       "      <td>227.717637</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>0.07270</td>\n",
       "      <td>0.05150</td>\n",
       "      <td>0.02040</td>\n",
       "      <td>0.01960</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>327.594444</td>\n",
       "      <td>113.605442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.4206</td>\n",
       "      <td>0.01551</td>\n",
       "      <td>0.00209</td>\n",
       "      <td>0.00312</td>\n",
       "      <td>0.00439</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>296.569594</td>\n",
       "      <td>330.400000</td>\n",
       "      <td>175.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>0.07190</td>\n",
       "      <td>0.09320</td>\n",
       "      <td>0.07330</td>\n",
       "      <td>0.04760</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.4097</td>\n",
       "      <td>253.331649</td>\n",
       "      <td>362.900000</td>\n",
       "      <td>127.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   H2S      N2     CO2      C1       C2       C3       C4       C5      C6  \\\n",
       "0  0.0  0.0025  0.0024  0.4091  0.10380  0.09010  0.05130  0.03280  0.0221   \n",
       "1  0.0  0.0034  0.0025  0.0407  0.03110  0.04880  0.05670  0.05520  0.0551   \n",
       "2  0.0  0.0015  0.0065  0.3048  0.07270  0.05150  0.02040  0.01960  0.0276   \n",
       "3  0.0  0.0007  0.0006  0.4206  0.01551  0.00209  0.00312  0.00439  0.0060   \n",
       "4  0.0  0.0178  0.0024  0.2504  0.07190  0.09320  0.07330  0.04760  0.0307   \n",
       "\n",
       "      C7+       MWC7+        Temp        Psat  \n",
       "0  0.2858  182.000000  422.038889  207.006803  \n",
       "1  0.7067  227.717637  344.000000   26.000000  \n",
       "2  0.4954  239.000000  327.594444  113.605442  \n",
       "3  0.5470  296.569594  330.400000  175.500000  \n",
       "4  0.4097  253.331649  362.900000  127.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22cc210",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"Psat\",axis = 1)\n",
    "y_train = train.Psat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979354e",
   "metadata": {},
   "source": [
    "                              #### Scalling Dataset ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65eac258",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a868c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following model path follows for all models location\n",
    "scaler_file = 'scaler.sav'\n",
    "pickle.dump(scaler , open(model_path+scaler_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec97328",
   "metadata": {},
   "source": [
    "##### .......................................................................................SectionBreak......................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd457a",
   "metadata": {},
   "source": [
    "## 1. Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94509d12",
   "metadata": {},
   "source": [
    "                              #### Calculate VIF for features ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5c39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF = [variance_inflation_factor(x_train , i) for i in range(0,x_train.shape[1])]  #shape is indicating number of columns which is argument for VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aca55c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURES</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H2S</td>\n",
       "      <td>1.132430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N2</td>\n",
       "      <td>1.182256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO2</td>\n",
       "      <td>1.315396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1</td>\n",
       "      <td>7.430661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C2</td>\n",
       "      <td>6.173437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C3</td>\n",
       "      <td>12.630215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C4</td>\n",
       "      <td>14.098662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C5</td>\n",
       "      <td>6.314385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C6</td>\n",
       "      <td>2.608042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C7+</td>\n",
       "      <td>8.776613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MWC7+</td>\n",
       "      <td>2.232995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Temp</td>\n",
       "      <td>1.879314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FEATURES        VIF\n",
       "0       H2S   1.132430\n",
       "1        N2   1.182256\n",
       "2       CO2   1.315396\n",
       "3        C1   7.430661\n",
       "4        C2   6.173437\n",
       "5        C3  12.630215\n",
       "6        C4  14.098662\n",
       "7        C5   6.314385\n",
       "8        C6   2.608042\n",
       "9       C7+   8.776613\n",
       "10    MWC7+   2.232995\n",
       "11     Temp   1.879314"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIF_DataFrame = pd.DataFrame(VIF)\n",
    "VIF_DataFrame = VIF_DataFrame.rename({0:\"VIF\"} , axis = 1)\n",
    "VIF_DataFrame[\"FEATURES\"] = X_train.columns\n",
    "VIF_DataFrame = VIF_DataFrame[[\"FEATURES\" , \"VIF\"]]\n",
    "VIF_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f544499",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF_DataFrame.to_excel(export_data_path+\"VIF.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d7d78",
   "metadata": {},
   "source": [
    "                              #### Model Fitting for linear regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a976edbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e563a",
   "metadata": {},
   "source": [
    "                         #### Model Summary #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e59072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_linear_summary = sm.add_constant(x_train, prepend=False)\n",
    "y_train_linear_summary = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a63555",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_summary = sm.OLS(y_train_linear_summary ,  x_train_linear_summary).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547ee538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Psat</td>       <th>  R-squared:         </th> <td>   0.945</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.942</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   284.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>2.59e-117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:17:49</td>     <th>  Log-Likelihood:    </th> <td> -907.55</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   210</td>      <th>  AIC:               </th> <td>   1841.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   197</td>      <th>  BIC:               </th> <td>   1885.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    4.0178</td> <td>    1.382</td> <td>    2.908</td> <td> 0.004</td> <td>    1.293</td> <td>    6.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    4.6453</td> <td>    1.412</td> <td>    3.290</td> <td> 0.001</td> <td>    1.861</td> <td>    7.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    6.2135</td> <td>    1.489</td> <td>    4.173</td> <td> 0.000</td> <td>    3.277</td> <td>    9.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   74.0409</td> <td>    3.539</td> <td>   20.920</td> <td> 0.000</td> <td>   67.061</td> <td>   81.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    6.7282</td> <td>    3.226</td> <td>    2.086</td> <td> 0.038</td> <td>    0.366</td> <td>   13.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>  -10.2829</td> <td>    4.614</td> <td>   -2.228</td> <td> 0.027</td> <td>  -19.383</td> <td>   -1.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    9.7436</td> <td>    4.875</td> <td>    1.999</td> <td> 0.047</td> <td>    0.129</td> <td>   19.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    1.5737</td> <td>    3.263</td> <td>    0.482</td> <td> 0.630</td> <td>   -4.860</td> <td>    8.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -4.2496</td> <td>    2.097</td> <td>   -2.027</td> <td> 0.044</td> <td>   -8.385</td> <td>   -0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    7.7609</td> <td>    3.847</td> <td>    2.018</td> <td> 0.045</td> <td>    0.175</td> <td>   15.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -2.6883</td> <td>    1.940</td> <td>   -1.386</td> <td> 0.167</td> <td>   -6.515</td> <td>    1.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   10.9566</td> <td>    1.780</td> <td>    6.156</td> <td> 0.000</td> <td>    7.446</td> <td>   14.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  145.2418</td> <td>    1.298</td> <td>  111.863</td> <td> 0.000</td> <td>  142.681</td> <td>  147.802</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.288</td> <th>  Durbin-Watson:     </th> <td>   2.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  25.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.343</td> <th>  Prob(JB):          </th> <td>2.35e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.578</td> <th>  Cond. No.          </th> <td>    10.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   Psat   R-squared:                       0.945\n",
       "Model:                            OLS   Adj. R-squared:                  0.942\n",
       "Method:                 Least Squares   F-statistic:                     284.5\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):          2.59e-117\n",
       "Time:                        12:17:49   Log-Likelihood:                -907.55\n",
       "No. Observations:                 210   AIC:                             1841.\n",
       "Df Residuals:                     197   BIC:                             1885.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             4.0178      1.382      2.908      0.004       1.293       6.743\n",
       "x2             4.6453      1.412      3.290      0.001       1.861       7.429\n",
       "x3             6.2135      1.489      4.173      0.000       3.277       9.150\n",
       "x4            74.0409      3.539     20.920      0.000      67.061      81.021\n",
       "x5             6.7282      3.226      2.086      0.038       0.366      13.090\n",
       "x6           -10.2829      4.614     -2.228      0.027     -19.383      -1.183\n",
       "x7             9.7436      4.875      1.999      0.047       0.129      19.358\n",
       "x8             1.5737      3.263      0.482      0.630      -4.860       8.008\n",
       "x9            -4.2496      2.097     -2.027      0.044      -8.385      -0.114\n",
       "x10            7.7609      3.847      2.018      0.045       0.175      15.347\n",
       "x11           -2.6883      1.940     -1.386      0.167      -6.515       1.138\n",
       "x12           10.9566      1.780      6.156      0.000       7.446      14.467\n",
       "const        145.2418      1.298    111.863      0.000     142.681     147.802\n",
       "==============================================================================\n",
       "Omnibus:                       14.288   Durbin-Watson:                   2.056\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               25.921\n",
       "Skew:                           0.343   Prob(JB):                     2.35e-06\n",
       "Kurtosis:                       4.578   Cond. No.                         10.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_summary.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba58d5",
   "metadata": {},
   "source": [
    "                                    #### Model Saving ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea5db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_file = 'linear_model.sav'\n",
    "pickle.dump(linear_regression , open(model_path+linear_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ad114",
   "metadata": {},
   "source": [
    "## 2. SVR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b9e79",
   "metadata": {},
   "source": [
    "                              #### Model tuning for svr Regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc19298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca54247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_para = {'C':range(4000,9000,100),'gamma':np.arange(0.000,0.002,0.0001)}\n",
    "svr_grid = GridSearchCV(svr_model,svr_para, cv = 5 , verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4616eefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4811 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': range(4000, 9000, 100),\n",
       "                         'gamma': array([0.    , 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007,\n",
       "       0.0008, 0.0009, 0.001 , 0.0011, 0.0012, 0.0013, 0.0014, 0.0015,\n",
       "       0.0016, 0.0017, 0.0018, 0.0019])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d18015b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5700, 'gamma': 0.0019}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e13728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_best_para = svr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b01ed33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=5700, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0019,\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_regression = SVR( C = svr_best_para[\"C\"],\n",
    "                      gamma = svr_best_para[\"gamma\"])\n",
    "svr_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c806ca9",
   "metadata": {},
   "source": [
    "                                          #### Model saveing #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0510d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_file = 'svr_model.sav'\n",
    "pickle.dump(svr_regression , open(model_path+svr_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a585c",
   "metadata": {},
   "source": [
    "## 3. Decision Tree Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101f30b",
   "metadata": {},
   "source": [
    "                                          #### Model tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "588eb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4011a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_para = {\n",
    "    'criterion': ['mse', 'mae'],\n",
    "    'max_depth' : range(2,32,1),\n",
    "    'min_samples_leaf' : range(1,7,1),\n",
    "    'min_samples_split': range(2,7,1),\n",
    "    'splitter' : ['best', 'random']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9ee8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3600 candidates, totalling 18000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 17672 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 18000 out of 18000 | elapsed:    9.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
       "                                             max_depth=None, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=None,\n",
       "                                             splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'criterion': ['mse', 'mae'], 'max_depth': range(2, 32),\n",
       "                         'min_samples_leaf': range(1, 7),\n",
       "                         'min_samples_split': range(2, 7),\n",
       "                         'splitter': ['best', 'random']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid = GridSearchCV(estimator=dt_model,\n",
    "                     param_grid=dt_para,\n",
    "                     cv=5,\n",
    "                     n_jobs =-1,\n",
    "                     verbose=3)\n",
    "dt_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fb0f315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mae',\n",
       " 'max_depth': 7,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 4,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbbbc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best_para = dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10ff71b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=7,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=6, min_samples_split=4,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=0, splitter='best')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_regression = DecisionTreeRegressor(criterion = dt_best_para[\"criterion\"],\n",
    "                                      max_depth = dt_best_para[\"max_depth\"],\n",
    "                                      min_samples_leaf = dt_best_para[\"min_samples_leaf\"],\n",
    "                                      min_samples_split = dt_best_para[\"min_samples_split\"],\n",
    "                                      splitter = dt_best_para[\"splitter\"],\n",
    "                                      random_state = 0\n",
    "                                      )\n",
    "\n",
    "dt_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48359c1d",
   "metadata": {},
   "source": [
    "                                          #### Model saveing #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94985ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'C:\\\\STUDY DRIVE\\\\Mtech New\\\\DENSITY PREDICTION\\\\MODELS\\\\SATURATION PRESSURE PREDICTION SATURATION DATASET 2 PART 4 MODELS\\\\'\n",
    "dt_file = 'dt_model.sav'\n",
    "pickle.dump(dt_regression , open(model_path+dt_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a483b4",
   "metadata": {},
   "source": [
    "## 4. Random forest Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bf2ff",
   "metadata": {},
   "source": [
    "                                          #### Model parameter tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1220c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd89700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_para = {\n",
    "    \"n_estimators\" : range(90,150,5),\n",
    "    'max_depth' : range(2,20,1),\n",
    "    'min_samples_leaf' : range(1,5,1),\n",
    "    'min_samples_split': range(2,5,1),\n",
    "    'max_features' : ['auto','log2']\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator=rf_model,\n",
    "                           param_grid=rf_para,\n",
    "                           cv=5,\n",
    "                           n_jobs =-1,\n",
    "                           verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "127b0485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5184 candidates, totalling 25920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3088 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4048 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5136 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6352 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7696 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 9168 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10768 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 12496 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 14352 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16336 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18448 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 20688 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 23056 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 25552 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 25920 out of 25920 | elapsed: 13.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(2, 20),\n",
       "                         'max_features': ['auto', 'log2'],\n",
       "                         'min_samples_leaf': range(1, 5),\n",
       "                         'min_samples_split': range(2, 5),\n",
       "                         'n_estimators': range(90, 150, 5)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ccb62c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 14,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 120}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "883a1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_para = rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8648f",
   "metadata": {},
   "source": [
    "                                          #### Model fiting with tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54b8ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=2,\n",
       "                      min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=120, n_jobs=None, oob_score=False,\n",
       "                      random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regression = RandomForestRegressor(n_estimators = rf_best_para[\"n_estimators\"],\n",
    "                                      max_depth = rf_best_para[\"max_depth\"],\n",
    "                                      min_samples_leaf =rf_best_para[\"min_samples_leaf\"],\n",
    "                                      min_samples_split = rf_best_para[\"min_samples_split\"],\n",
    "                                      max_features = rf_best_para[\"max_features\"],\n",
    "                                      random_state = 0\n",
    "                                      )\n",
    "\n",
    "rf_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2435ab",
   "metadata": {},
   "source": [
    "                                          #### Model Saving #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc9c0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_file = 'rf_model.sav'\n",
    "pickle.dump(rf_regression , open(model_path+rf_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ef5e6",
   "metadata": {},
   "source": [
    "## 5. KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90427214",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4294a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_para = {\"n_neighbors\"  : range(2,11)}\n",
    "knn_grid = GridSearchCV(knn_model,knn_para, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c8283e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                           metric='minkowski',\n",
       "                                           metric_params=None, n_jobs=None,\n",
       "                                           n_neighbors=5, p=2,\n",
       "                                           weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'n_neighbors': range(2, 11)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "786fbbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 2}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7d26ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_para = knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a5cff0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_regression = KNeighborsRegressor( n_neighbors = knn_best_para[\"n_neighbors\"])\n",
    "\n",
    "knn_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d766200",
   "metadata": {},
   "source": [
    "                                          #### Model Saving #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb4419e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_file = 'knn_model.sav'\n",
    "pickle.dump(knn_regression , open(model_path+knn_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02bc62",
   "metadata": {},
   "source": [
    "## 6. XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db23419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15b030c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_para={\n",
    "   \n",
    "    'learning_rate': np.arange(0.1,0.2,0.04),\n",
    "    'max_depth': range(2,10,1),\n",
    "    'n_estimators':range(90,150,10),\n",
    "    \"gamma\" : np.arange(0.1,0.5,0.3),\n",
    "    \"min_child_weight\": range(1,10,2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d68cb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = GridSearchCV(xgb_model,xgb_para, cv = 5 , verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5cda953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5392 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6256 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estima...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'gamma': array([0.1, 0.4]),\n",
       "                         'learning_rate': array([0.1 , 0.14, 0.18]),\n",
       "                         'max_depth': range(2, 10),\n",
       "                         'min_child_weight': range(1, 10, 2),\n",
       "                         'n_estimators': range(90, 150, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "278ff28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.4,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 5,\n",
       " 'n_estimators': 90}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76929a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_para = xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cb1d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.4, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=90, n_jobs=8, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_regression = XGBRegressor(\n",
    "                    learning_rate = xgb_best_para[\"learning_rate\"],\n",
    "                    max_depth = xgb_best_para[\"max_depth\"],\n",
    "                    n_estimators = xgb_best_para[\"n_estimators\"],\n",
    "                    gamma = xgb_best_para[\"gamma\"],\n",
    "                    min_child_weight = xgb_best_para[\"min_child_weight\"]\n",
    "                    )\n",
    "xgb_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4ef0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_file = 'xgb_model.sav'\n",
    "pickle.dump(xgb_regression , open(model_path+xgb_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70110f",
   "metadata": {},
   "source": [
    "## 7. ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f91a2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=x_train.shape[1]))\n",
    "    \n",
    "    for i in range(hp.Int('layers', 2, 15)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=3,\n",
    "                                            max_value=15,\n",
    "                                            step=1),\n",
    "                               activation=hp.Choice('act_' + str(i),[\"relu\",\"tanh\"])))\n",
    "        \n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff70014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_trials=50,\n",
    "    executions_per_trial=3,\n",
    "    project_name = \"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee299d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "act_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "act_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f76214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5e0a487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 11s]\n",
      "val_mean_squared_error: 12491.663736979166\n",
      "\n",
      "Best val_mean_squared_error So Far: 345.9986877441406\n",
      "Total elapsed time: 00h 09m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train.values,\n",
    "             epochs=100,\n",
    "             validation_split = 0.20,\n",
    "             callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1975b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\ANN\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_squared_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 11\n",
      "units_0: 11\n",
      "act_0: tanh\n",
      "units_1: 9\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 6\n",
      "act_2: tanh\n",
      "units_3: 4\n",
      "act_3: tanh\n",
      "units_4: 11\n",
      "act_4: tanh\n",
      "units_5: 8\n",
      "act_5: tanh\n",
      "units_6: 8\n",
      "act_6: relu\n",
      "units_7: 8\n",
      "act_7: tanh\n",
      "units_8: 5\n",
      "act_8: relu\n",
      "units_9: 9\n",
      "act_9: relu\n",
      "units_10: 11\n",
      "act_10: relu\n",
      "units_11: 6\n",
      "act_11: tanh\n",
      "units_12: 5\n",
      "act_12: tanh\n",
      "units_13: 10\n",
      "act_13: tanh\n",
      "Score: 345.9986877441406\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 3\n",
      "act_0: tanh\n",
      "units_1: 15\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 7\n",
      "act_2: relu\n",
      "units_3: 14\n",
      "act_3: relu\n",
      "units_4: 4\n",
      "act_4: tanh\n",
      "units_5: 14\n",
      "act_5: tanh\n",
      "units_6: 11\n",
      "act_6: relu\n",
      "units_7: 4\n",
      "act_7: relu\n",
      "units_8: 3\n",
      "act_8: tanh\n",
      "units_9: 14\n",
      "act_9: tanh\n",
      "units_10: 8\n",
      "act_10: tanh\n",
      "units_11: 4\n",
      "act_11: relu\n",
      "units_12: 13\n",
      "act_12: tanh\n",
      "units_13: 7\n",
      "act_13: relu\n",
      "Score: 402.15643310546875\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 4\n",
      "units_0: 3\n",
      "act_0: tanh\n",
      "units_1: 15\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 13\n",
      "act_2: relu\n",
      "units_3: 9\n",
      "act_3: relu\n",
      "units_4: 10\n",
      "act_4: relu\n",
      "units_5: 4\n",
      "act_5: relu\n",
      "units_6: 14\n",
      "act_6: relu\n",
      "units_7: 5\n",
      "act_7: relu\n",
      "units_8: 12\n",
      "act_8: relu\n",
      "units_9: 5\n",
      "act_9: tanh\n",
      "units_10: 11\n",
      "act_10: tanh\n",
      "units_11: 11\n",
      "act_11: tanh\n",
      "units_12: 5\n",
      "act_12: relu\n",
      "units_13: 11\n",
      "act_13: tanh\n",
      "units_14: 13\n",
      "act_14: tanh\n",
      "Score: 502.1159261067708\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 7\n",
      "units_0: 5\n",
      "act_0: relu\n",
      "units_1: 10\n",
      "act_1: tanh\n",
      "learning_rate: 0.001\n",
      "units_2: 11\n",
      "act_2: tanh\n",
      "units_3: 14\n",
      "act_3: relu\n",
      "units_4: 8\n",
      "act_4: relu\n",
      "units_5: 8\n",
      "act_5: relu\n",
      "units_6: 8\n",
      "act_6: relu\n",
      "units_7: 10\n",
      "act_7: tanh\n",
      "units_8: 14\n",
      "act_8: tanh\n",
      "units_9: 5\n",
      "act_9: relu\n",
      "units_10: 4\n",
      "act_10: tanh\n",
      "units_11: 3\n",
      "act_11: relu\n",
      "units_12: 11\n",
      "act_12: tanh\n",
      "units_13: 14\n",
      "act_13: tanh\n",
      "Score: 1061.07470703125\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 6\n",
      "units_0: 6\n",
      "act_0: relu\n",
      "units_1: 4\n",
      "act_1: relu\n",
      "learning_rate: 0.001\n",
      "units_2: 14\n",
      "act_2: tanh\n",
      "units_3: 7\n",
      "act_3: relu\n",
      "units_4: 13\n",
      "act_4: relu\n",
      "units_5: 12\n",
      "act_5: relu\n",
      "units_6: 9\n",
      "act_6: relu\n",
      "units_7: 4\n",
      "act_7: tanh\n",
      "units_8: 3\n",
      "act_8: relu\n",
      "units_9: 14\n",
      "act_9: relu\n",
      "units_10: 13\n",
      "act_10: relu\n",
      "units_11: 13\n",
      "act_11: tanh\n",
      "units_12: 5\n",
      "act_12: tanh\n",
      "units_13: 5\n",
      "act_13: tanh\n",
      "Score: 1115.647237141927\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 9\n",
      "act_0: tanh\n",
      "units_1: 10\n",
      "act_1: relu\n",
      "learning_rate: 0.001\n",
      "units_2: 6\n",
      "act_2: relu\n",
      "units_3: 13\n",
      "act_3: tanh\n",
      "units_4: 7\n",
      "act_4: relu\n",
      "units_5: 10\n",
      "act_5: tanh\n",
      "units_6: 15\n",
      "act_6: tanh\n",
      "units_7: 7\n",
      "act_7: tanh\n",
      "units_8: 13\n",
      "act_8: relu\n",
      "units_9: 3\n",
      "act_9: tanh\n",
      "units_10: 10\n",
      "act_10: relu\n",
      "units_11: 14\n",
      "act_11: relu\n",
      "units_12: 6\n",
      "act_12: tanh\n",
      "units_13: 4\n",
      "act_13: tanh\n",
      "units_14: 3\n",
      "act_14: relu\n",
      "Score: 2650.8759765625\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 4\n",
      "units_0: 4\n",
      "act_0: tanh\n",
      "units_1: 6\n",
      "act_1: tanh\n",
      "learning_rate: 0.001\n",
      "units_2: 13\n",
      "act_2: relu\n",
      "units_3: 9\n",
      "act_3: relu\n",
      "units_4: 10\n",
      "act_4: tanh\n",
      "units_5: 11\n",
      "act_5: tanh\n",
      "units_6: 12\n",
      "act_6: tanh\n",
      "units_7: 3\n",
      "act_7: relu\n",
      "units_8: 8\n",
      "act_8: relu\n",
      "units_9: 7\n",
      "act_9: relu\n",
      "units_10: 10\n",
      "act_10: tanh\n",
      "units_11: 3\n",
      "act_11: tanh\n",
      "units_12: 4\n",
      "act_12: relu\n",
      "units_13: 4\n",
      "act_13: tanh\n",
      "Score: 5381.131754557292\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 15\n",
      "units_0: 9\n",
      "act_0: tanh\n",
      "units_1: 3\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 14\n",
      "act_2: relu\n",
      "units_3: 12\n",
      "act_3: relu\n",
      "units_4: 9\n",
      "act_4: tanh\n",
      "units_5: 9\n",
      "act_5: tanh\n",
      "units_6: 3\n",
      "act_6: relu\n",
      "units_7: 14\n",
      "act_7: tanh\n",
      "units_8: 12\n",
      "act_8: relu\n",
      "units_9: 8\n",
      "act_9: tanh\n",
      "units_10: 4\n",
      "act_10: relu\n",
      "units_11: 9\n",
      "act_11: tanh\n",
      "units_12: 10\n",
      "act_12: relu\n",
      "units_13: 11\n",
      "act_13: relu\n",
      "units_14: 3\n",
      "act_14: relu\n",
      "Score: 6240.922200520833\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 9\n",
      "units_0: 6\n",
      "act_0: tanh\n",
      "units_1: 13\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 13\n",
      "act_2: relu\n",
      "units_3: 7\n",
      "act_3: relu\n",
      "units_4: 11\n",
      "act_4: relu\n",
      "units_5: 3\n",
      "act_5: relu\n",
      "units_6: 9\n",
      "act_6: tanh\n",
      "units_7: 14\n",
      "act_7: relu\n",
      "units_8: 7\n",
      "act_8: relu\n",
      "units_9: 10\n",
      "act_9: tanh\n",
      "units_10: 11\n",
      "act_10: tanh\n",
      "units_11: 11\n",
      "act_11: relu\n",
      "units_12: 6\n",
      "act_12: tanh\n",
      "units_13: 6\n",
      "act_13: tanh\n",
      "Score: 6257.62255859375\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 15\n",
      "units_0: 14\n",
      "act_0: relu\n",
      "units_1: 14\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 14\n",
      "act_2: tanh\n",
      "units_3: 11\n",
      "act_3: tanh\n",
      "units_4: 11\n",
      "act_4: tanh\n",
      "units_5: 5\n",
      "act_5: tanh\n",
      "units_6: 6\n",
      "act_6: tanh\n",
      "units_7: 8\n",
      "act_7: relu\n",
      "units_8: 10\n",
      "act_8: relu\n",
      "units_9: 8\n",
      "act_9: relu\n",
      "units_10: 13\n",
      "act_10: tanh\n",
      "units_11: 11\n",
      "act_11: relu\n",
      "units_12: 14\n",
      "act_12: relu\n",
      "units_13: 14\n",
      "act_13: relu\n",
      "units_14: 11\n",
      "act_14: relu\n",
      "Score: 6338.025065104167\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e653f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 11)                143       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 60        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 28        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 11)                55        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 9)                 54        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 11)                110       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "'''This link has proved that while showing summary of result number of unit shows higher than \n",
    "    actual number of layers which reported as bug in official keras documents.\n",
    "    However it has been proven that finalized model description can be obtained by following.\n",
    "    Use number of layer shown as number_layer arguments [i.g best model with number_layer = 4\n",
    "    units_0 to units_3 in our case. Avoid higher values.]\n",
    "    \n",
    "    https://github.com/keras-team/keras-tuner/issues/66#issuecomment-525923517'''\n",
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c50b540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_best_para = tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7686141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regression = Sequential()\n",
    "\n",
    "\n",
    "#Input layer \n",
    "ann_regression.add(tf.keras.Input(shape=x_train.shape[1]))\n",
    "\n",
    "limit = ann_best_para[\"layers\"] \n",
    "\n",
    "#Number of hidden layer\n",
    "for i in range(0, limit) :\n",
    "    ann_regression.add(Dense(units=ann_best_para['units_'+str(i)],activation=ann_best_para['act_'+str(i)]))\n",
    "\n",
    "    \n",
    "#Last Output Layer\n",
    "ann_regression.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "\n",
    "\n",
    "#ANN compilation with loss function and optimization\n",
    "ann_regression.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=ann_best_para['learning_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0081ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_final = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3bf2497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/6 [==============================] - 1s 29ms/step - loss: 25681.0625 - val_loss: 33032.4648\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 25519.0215 - val_loss: 32627.6641\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 25028.6543 - val_loss: 31687.0293\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 24036.9297 - val_loss: 30088.0293\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 22410.2656 - val_loss: 27460.8750\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 19772.0371 - val_loss: 23295.7773\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 15810.9951 - val_loss: 17473.6465\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 11068.5293 - val_loss: 10936.3584\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6904.5767 - val_loss: 6734.9858\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6344.3877 - val_loss: 6308.4243\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6843.3765 - val_loss: 6255.6221\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6051.9902 - val_loss: 6867.6011\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5956.3970 - val_loss: 7336.3662\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6062.3335 - val_loss: 7364.4463\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6022.2124 - val_loss: 7050.3086\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5960.4414 - val_loss: 6760.4473\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5944.3750 - val_loss: 6722.9746\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5982.1011 - val_loss: 6845.7397\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5968.0078 - val_loss: 6570.0044\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5996.6255 - val_loss: 6581.7900\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5952.3237 - val_loss: 6876.2134\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5971.5122 - val_loss: 7121.7002\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5966.9204 - val_loss: 6842.6436\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5948.9829 - val_loss: 6662.5850\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5953.7188 - val_loss: 6611.9243\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5945.2754 - val_loss: 6803.3794\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5952.9932 - val_loss: 6870.8037\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5960.2446 - val_loss: 6964.7554\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5941.9194 - val_loss: 6683.7002\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5942.0508 - val_loss: 6515.0552\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5993.6768 - val_loss: 6591.4976\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5974.8999 - val_loss: 6857.2939\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5955.5156 - val_loss: 6798.8750\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5947.1602 - val_loss: 6945.9102\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5969.1553 - val_loss: 6977.5229\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5970.7896 - val_loss: 6893.2002\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5954.1230 - val_loss: 6894.7681\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5954.2930 - val_loss: 6928.7319\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5955.9204 - val_loss: 6888.9741\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5938.0571 - val_loss: 6728.3706\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5943.2422 - val_loss: 6522.7788\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5990.1621 - val_loss: 6579.5508\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5931.4653 - val_loss: 7026.2007\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6008.0537 - val_loss: 7454.5259\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6056.6338 - val_loss: 7125.1592\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5957.6860 - val_loss: 6700.5127\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5947.4766 - val_loss: 6460.5015\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6020.6348 - val_loss: 6592.4702\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5926.2017 - val_loss: 6956.8867\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5955.8472 - val_loss: 6977.4375\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5958.0537 - val_loss: 6881.0781\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5954.3408 - val_loss: 6725.4785\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5971.6489 - val_loss: 6641.6338\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5957.9834 - val_loss: 6814.2827\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5946.2944 - val_loss: 6730.2598\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5957.9863 - val_loss: 6621.7798\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5976.7944 - val_loss: 6817.3931\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5946.2539 - val_loss: 6861.6421\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5944.2251 - val_loss: 6810.2134\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5942.6191 - val_loss: 6807.6523\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6020.6323 - val_loss: 6950.4004\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5945.0381 - val_loss: 6804.1191\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5946.1104 - val_loss: 6811.4365\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5937.9106 - val_loss: 6658.8447\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5964.9355 - val_loss: 6573.2769\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5956.8037 - val_loss: 6957.9189\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5950.5337 - val_loss: 7114.9517\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5971.7119 - val_loss: 6926.0029\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5907.6353 - val_loss: 6583.8096\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6067.7646 - val_loss: 6355.1055\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6042.0913 - val_loss: 6652.3228\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 6105.9346 - val_loss: 7059.4741\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5983.9072 - val_loss: 6525.9302\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5992.8540 - val_loss: 6554.9731\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5959.2607 - val_loss: 6751.8452\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5943.9971 - val_loss: 6838.4761\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5988.3647 - val_loss: 7005.9165\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5946.1079 - val_loss: 6773.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5958.9502 - val_loss: 6630.1665\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5947.3696 - val_loss: 6766.5425\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5953.3154 - val_loss: 6830.9165\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5994.0015 - val_loss: 7077.7417\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5971.8242 - val_loss: 6899.9897\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5955.0474 - val_loss: 6694.1294\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5949.6353 - val_loss: 6778.3066\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5954.3848 - val_loss: 6830.7930\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5977.3574 - val_loss: 6621.2344\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5945.6411 - val_loss: 6959.4600\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5564.4751 - val_loss: 6444.8896\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5216.6245 - val_loss: 5457.3735\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 3819.3147 - val_loss: 4499.4165\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 3645.6917 - val_loss: 5066.5259\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 4240.2715 - val_loss: 3857.1257\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 3516.0005 - val_loss: 3266.8203\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 2851.8730 - val_loss: 2733.0254\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2813.0737 - val_loss: 2412.4568\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2307.5254 - val_loss: 2225.9148\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 1389.77 - 0s 6ms/step - loss: 2086.9348 - val_loss: 1889.1321\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1818.3843 - val_loss: 1784.8083\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1653.4646 - val_loss: 1668.8569\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1606.0476 - val_loss: 1537.4640\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1690.2483 - val_loss: 1496.9113\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1623.8135 - val_loss: 1502.3376\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1704.3748 - val_loss: 1510.4017\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1696.3793 - val_loss: 1474.4713\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1700.4747 - val_loss: 1557.4227\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1721.1868 - val_loss: 1556.7764\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1671.9312 - val_loss: 1487.8423\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1684.2142 - val_loss: 1472.6921\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1663.1521 - val_loss: 1470.1661\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1653.3896 - val_loss: 1432.4136\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1659.0967 - val_loss: 1491.4897\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1662.9847 - val_loss: 1469.3616\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1638.5612 - val_loss: 1423.6693\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1645.1996 - val_loss: 1430.2126\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1603.1910 - val_loss: 1469.6648\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1591.6151 - val_loss: 1466.5647\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1582.4928 - val_loss: 1370.3110\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1571.1136 - val_loss: 1382.6849\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1568.3811 - val_loss: 1382.4385\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1571.0813 - val_loss: 1287.2213\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1563.8513 - val_loss: 1265.1713\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1578.0714 - val_loss: 1133.8068\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1603.8342 - val_loss: 1537.9351\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1968.7990 - val_loss: 1370.9819\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1664.2574 - val_loss: 1384.2810\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1708.2095 - val_loss: 1491.8427\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1471.0742 - val_loss: 1534.9524\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1388.4850 - val_loss: 1220.7257\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1370.6278 - val_loss: 1088.3584\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1422.2638 - val_loss: 1112.5168\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1292.7295 - val_loss: 1234.9193\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1331.0463 - val_loss: 1104.8225\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1315.4137 - val_loss: 1150.8287\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1568.5916 - val_loss: 1160.5912\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1328.9541 - val_loss: 1285.6873\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1290.7572 - val_loss: 1134.9417\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1273.0602 - val_loss: 1169.8635\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1235.6995 - val_loss: 1085.0651\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1129.8376 - val_loss: 1059.0585\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1234.6630 - val_loss: 1134.5208\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1047.5228 - val_loss: 895.7447\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 853.6769 - val_loss: 785.1107\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 779.3104 - val_loss: 804.2463\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 695.0261 - val_loss: 633.0215\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 554.8200 - val_loss: 754.4550\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 658.6915 - val_loss: 1037.7377\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 916.1959 - val_loss: 667.4849\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 744.8383 - val_loss: 728.0009\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 681.6479 - val_loss: 888.7033\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 641.7056 - val_loss: 654.3022\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 548.5066 - val_loss: 719.6870\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 510.3152 - val_loss: 532.1976\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 455.3456 - val_loss: 674.6185\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 520.5394 - val_loss: 558.4253\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 493.2748 - val_loss: 583.3598\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 482.6243 - val_loss: 587.1000\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 477.2559 - val_loss: 762.6891\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 463.4879 - val_loss: 578.1626\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 417.6850 - val_loss: 632.6890\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 374.5793 - val_loss: 584.0590\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 300.6197 - val_loss: 528.4480\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 282.1563 - val_loss: 661.8312\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 287.2049 - val_loss: 521.3000\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 279.5627 - val_loss: 535.7039\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 271.0932 - val_loss: 736.6878\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 281.1464 - val_loss: 515.6646\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 250.6893 - val_loss: 472.5641\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 259.6261 - val_loss: 677.2827\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 243.6162 - val_loss: 457.9020\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 249.9394 - val_loss: 591.4166\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 260.7480 - val_loss: 643.4177\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 234.1148 - val_loss: 456.6360\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 224.7491 - val_loss: 688.6240\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 246.1306 - val_loss: 465.9441\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 227.8924 - val_loss: 556.1625\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 232.5046 - val_loss: 554.0387\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 210.4677 - val_loss: 462.8963\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 203.0161 - val_loss: 453.9980\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 160.9731 - val_loss: 458.1858\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 178.8345 - val_loss: 510.8515\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 173.5825 - val_loss: 380.5947\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 154.6514 - val_loss: 449.5339\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 147.5326 - val_loss: 401.7975\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 144.4392 - val_loss: 421.2558\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 162.6500 - val_loss: 355.7255\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 147.6725 - val_loss: 431.0776\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 160.2029 - val_loss: 483.1682\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 132.0905 - val_loss: 357.4020\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 121.9472 - val_loss: 421.5384\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 127.7517 - val_loss: 402.4182\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 126.7494 - val_loss: 398.4674\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 187.0250 - val_loss: 431.9301\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 168.0993 - val_loss: 433.1816\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 120.8025 - val_loss: 367.6747\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 101.8055 - val_loss: 380.6952\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 109.5203 - val_loss: 393.2933\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 99.9856 - val_loss: 324.6686\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 96.2550 - val_loss: 374.4691\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 93.5581 - val_loss: 372.6086\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 95.4446 - val_loss: 490.1498\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 104.2570 - val_loss: 390.7381\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 104.5271 - val_loss: 384.8355\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 101.5028 - val_loss: 371.6841\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 83.0983 - val_loss: 436.8437\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 74.9634 - val_loss: 353.9477\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 83.8282 - val_loss: 396.8517\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 78.7370 - val_loss: 500.8770\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 122.1167 - val_loss: 393.7592\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 119.4626 - val_loss: 395.7737\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 104.1187 - val_loss: 450.9504\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 101.1934 - val_loss: 419.8842\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 103.2916 - val_loss: 333.1629\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 100.1628 - val_loss: 344.4564\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 87.0361 - val_loss: 394.9915\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 79.4874 - val_loss: 401.1570\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 79.6647 - val_loss: 346.9938\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 69.1353 - val_loss: 394.4561\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 77.2382 - val_loss: 351.8800\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 89.4963 - val_loss: 339.0325\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 70.7444 - val_loss: 340.8365\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 80.8222 - val_loss: 350.7480\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 81.2190 - val_loss: 451.8529\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 87.6953 - val_loss: 436.4306\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 154.3329 - val_loss: 442.6696\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 152.2734 - val_loss: 509.2713\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 139.1722 - val_loss: 510.7841\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 107.7449 - val_loss: 343.7746\n",
      "Epoch 229/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 118.7074 - val_loss: 445.9875\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 106.8143 - val_loss: 359.0236\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 90.4310 - val_loss: 407.0402\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 85.4910 - val_loss: 379.2382\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 73.0676 - val_loss: 417.0775\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 71.7868 - val_loss: 378.6412\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 69.9060 - val_loss: 360.1390\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 61.4631 - val_loss: 428.4085\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 67.3015 - val_loss: 372.7594\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 72.0534 - val_loss: 370.6554\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 77.6989 - val_loss: 448.8414\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 86.7446 - val_loss: 360.3894\n",
      "Epoch 241/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 80.0597 - val_loss: 381.2519\n",
      "Epoch 242/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 74.6292 - val_loss: 386.2347\n",
      "Epoch 243/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 63.5151 - val_loss: 405.3254\n",
      "Epoch 244/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 61.2756 - val_loss: 372.2935\n",
      "Epoch 245/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 61.1079 - val_loss: 388.4921\n",
      "Epoch 246/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 61.3810 - val_loss: 427.7452\n",
      "Epoch 247/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 66.3675 - val_loss: 381.8893\n",
      "Epoch 248/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 65.5809 - val_loss: 426.7808\n",
      "Epoch 249/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 68.8547 - val_loss: 368.6927\n",
      "Epoch 250/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 73.6647 - val_loss: 393.9632\n",
      "Epoch 251/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 73.7198 - val_loss: 399.0899\n",
      "Epoch 252/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 64.1817 - val_loss: 381.1597\n",
      "Epoch 253/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 64.1575 - val_loss: 389.1555\n",
      "Epoch 254/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 58.5127 - val_loss: 370.1298\n",
      "Epoch 255/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 60.7285 - val_loss: 397.1556\n",
      "Epoch 256/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 59.5369 - val_loss: 366.8900\n",
      "Epoch 257/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 69.7725 - val_loss: 467.4639\n",
      "Epoch 258/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 78.4994 - val_loss: 382.6186\n",
      "Epoch 259/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 77.5617 - val_loss: 372.4488\n",
      "Epoch 260/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 84.9049 - val_loss: 470.3973\n",
      "Epoch 261/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 89.0116 - val_loss: 401.8176\n",
      "Epoch 262/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 83.1165 - val_loss: 327.6890\n",
      "Epoch 263/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 79.4866 - val_loss: 448.2313\n",
      "Epoch 264/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 68.8025 - val_loss: 422.5967\n",
      "Epoch 265/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 67.2411 - val_loss: 402.0575\n",
      "Epoch 266/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 64.1637 - val_loss: 347.8328\n",
      "Epoch 267/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 60.1252 - val_loss: 351.2602\n",
      "Epoch 268/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 62.3036 - val_loss: 412.8708\n",
      "Epoch 269/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 59.4405 - val_loss: 370.1686\n",
      "Epoch 270/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 53.0763 - val_loss: 402.3530\n",
      "Epoch 271/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 59.0973 - val_loss: 370.9190\n",
      "Epoch 272/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 56.3796 - val_loss: 355.7146\n",
      "Epoch 273/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 61.4999 - val_loss: 383.9833\n",
      "Epoch 274/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 66.5182 - val_loss: 363.4902\n",
      "Epoch 275/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 54.2723 - val_loss: 416.0401\n",
      "Epoch 276/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 56.2649 - val_loss: 405.4482\n",
      "Epoch 277/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 54.1831 - val_loss: 384.4407\n",
      "Epoch 278/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 56.8559 - val_loss: 372.3696\n",
      "Epoch 279/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 55.6229 - val_loss: 357.3622\n",
      "Epoch 280/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 57.6477 - val_loss: 385.6205\n",
      "Epoch 281/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 54.4805 - val_loss: 362.6892\n",
      "Epoch 282/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 62.3491 - val_loss: 407.7568\n",
      "Epoch 283/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 63.3607 - val_loss: 441.0430\n",
      "Epoch 284/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 61.7955 - val_loss: 374.3327\n",
      "Epoch 285/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 63.6827 - val_loss: 351.8196\n",
      "Epoch 286/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 65.6701 - val_loss: 430.1359\n",
      "Epoch 287/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 59.7907 - val_loss: 368.9979\n",
      "Epoch 288/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 60.1700 - val_loss: 394.7458\n",
      "Epoch 289/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 56.4059 - val_loss: 368.2392\n",
      "Epoch 290/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 53.2034 - val_loss: 366.4792\n",
      "Epoch 291/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 54.3867 - val_loss: 425.4094\n",
      "Epoch 292/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 52.7396 - val_loss: 390.3058\n",
      "Epoch 293/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 52.7525 - val_loss: 381.1654\n",
      "Epoch 294/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 51.2525 - val_loss: 362.5237\n",
      "Epoch 295/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 57.7299 - val_loss: 407.1137\n",
      "Epoch 296/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 52.9288 - val_loss: 363.6408\n",
      "Epoch 297/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 50.7008 - val_loss: 388.2951\n",
      "Epoch 298/1000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 52.3993 - val_loss: 420.1532\n",
      "Epoch 00298: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1888b336580>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_regression.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=1000,\n",
    "          validation_split=0.20, \n",
    "          verbose=1,\n",
    "          callbacks=[early_stop_final],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39a84960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25681.062500</td>\n",
       "      <td>33032.464844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25519.021484</td>\n",
       "      <td>32627.664062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25028.654297</td>\n",
       "      <td>31687.029297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24036.929688</td>\n",
       "      <td>30088.029297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22410.265625</td>\n",
       "      <td>27460.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>51.252464</td>\n",
       "      <td>362.523682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>57.729904</td>\n",
       "      <td>407.113739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>52.928814</td>\n",
       "      <td>363.640778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>50.700817</td>\n",
       "      <td>388.295074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>52.399269</td>\n",
       "      <td>420.153229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss      val_loss\n",
       "0    25681.062500  33032.464844\n",
       "1    25519.021484  32627.664062\n",
       "2    25028.654297  31687.029297\n",
       "3    24036.929688  30088.029297\n",
       "4    22410.265625  27460.875000\n",
       "..            ...           ...\n",
       "293     51.252464    362.523682\n",
       "294     57.729904    407.113739\n",
       "295     52.928814    363.640778\n",
       "296     50.700817    388.295074\n",
       "297     52.399269    420.153229\n",
       "\n",
       "[298 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ann_regression.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c66b46e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann_regression_df = pd.DataFrame(ann_regression.history.history)\n",
    "ann_regression_df[[\"loss\",\"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3f7a3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 11)                143       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 6)                 60        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 28        \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 9)                 54        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 11)                110       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6b184ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 640us/step - loss: 129.3265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "129.3265380859375"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_regression.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e7cc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regression_df.to_csv(export_data_path+\"LOSS_VALUES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91f7c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file = 'ann_model.h5'\n",
    "ann_regression.save(model_path+ann_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9caad5",
   "metadata": {},
   "source": [
    "###  ALL MODELS TRAINED ARE LOCATED AT THE LOCATION DEFINED BY USER AT CELL 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f44e3",
   "metadata": {},
   "source": [
    ".......................................THE END.........................................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2739cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c5ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
